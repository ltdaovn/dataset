{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thegioididong_crawling_28_08.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ckY1qfrW5rCm",
        "0qsQSzz-5swP"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ltdaovn/dataset/blob/master/TheGioiDiDong/thegioididong_crawling_28_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HX9nyIJ5nVP"
      },
      "source": [
        "# install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hBAFJgp4yra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79031bb1-4aa4-401d-ac01-db62dc722dec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LdzrO5hk7t7"
      },
      "source": [
        "!pip install html5lib\n",
        "!pip install lxml\n",
        "\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckY1qfrW5rCm"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7sjbAo0urLr"
      },
      "source": [
        "import sys\n",
        "from selenium import webdriver\n",
        "import time\n",
        "\n",
        "import bs4\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qsQSzz-5swP"
      },
      "source": [
        "# setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgksxOZr50Qw"
      },
      "source": [
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLTp2BhXdJBI"
      },
      "source": [
        "SESSION = requests.Session()\n",
        "HEADERS = {\n",
        "    'user-agent': ('Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 '\n",
        "                   '(KHTML, like Gecko) Chrome/48.0.2564.109 Safari/537.36')\n",
        "}\n",
        "\n",
        "BASE_URL = 'https://www.thegioididong.com/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Tgo-lEo8nK"
      },
      "source": [
        "# function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_8jAxNdpj6d"
      },
      "source": [
        "def crawling(url,time_sleeping = 10):\n",
        "    print('- webdriver is starting ... ')\n",
        "    wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "    wd.get(url)\n",
        "    time.sleep(time_sleeping)\n",
        "    page = wd.page_source\n",
        "    soup = BeautifulSoup(page, 'html.parser')\n",
        "    wd.close()\n",
        "\n",
        "    return soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uIByr8So-DI"
      },
      "source": [
        "# lấy link những item xuất hiện trên một trang đã được tải đầy đủ theo type và end_page\n",
        "def get_all_item_in_page(type,end_page):\n",
        "\n",
        "    url = BASE_URL + type + str(end_page)\n",
        "    print(url)\n",
        "    soup = crawling(url)\n",
        "\n",
        "    all_item = soup.find_all('li', {'class': ['item','ajaxed',' item ']})\n",
        "\n",
        "    if len(all_item) > 0:\n",
        "        print('- Found {number:} items'.format(number = len(all_item)))\n",
        "        # href_all_item_in_page = [a.find('a').get('href') for a in all_item]\n",
        "        href_all_item_in_page = []\n",
        "\n",
        "        for a in all_item:\n",
        "            try:\n",
        "                h = a.find('a').get('href')\n",
        "                href_all_item_in_page.append(h)\n",
        "            except:\n",
        "                print(a)\n",
        "\n",
        "        if len(href_all_item_in_page) > 0:\n",
        "            print('- Found links of {number:} items'.format(number = len(href_all_item_in_page)))\n",
        "            return href_all_item_in_page\n",
        "        else:\n",
        "            print('- Not find the link of the item')\n",
        "            return None\n",
        "    else:\n",
        "        print('- No item found')\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-H8nJ0s3RI5"
      },
      "source": [
        "#get_all_item_in_page('dtdd#c=42&o=9&pi=',10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHkn7GD9BQSQ"
      },
      "source": [
        "def rating_processing(rating):\n",
        "    num_star = 0\n",
        "    comment_star = rating.find('div',{'class':['comment-star']})\n",
        "    for star in comment_star.find_all('i'):\n",
        "        if star['class'][0] == 'icon-star':\n",
        "            num_star += 1\n",
        "\n",
        "    cmt_txt = rating.find('p',{'class':['cmt-txt']})\n",
        "    comment = cmt_txt.text\n",
        "\n",
        "    txtname = rating.find('p',{'class':['txtname']})\n",
        "    username = txtname.text\n",
        "\n",
        "    rating = {\n",
        "        'username': username,\n",
        "        'comment': comment,\n",
        "        'star': num_star,\n",
        "        }\n",
        "    #print(rating)\n",
        "    return rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDYaxz681Mt-"
      },
      "source": [
        "def get_rating(rating_page_url,session, headers, except_loop = 8,num_page = 1):\n",
        "\n",
        "    try:\n",
        "        url = rating_page_url+'?p='+str(num_page)\n",
        "        response = session.get(url,headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    except:\n",
        "        except_loop -= 1\n",
        "        if except_loop > 0:\n",
        "            session = requests.Session() #requests lại\n",
        "            get_rating(rating_page_url, session, headers ,except_loop = except_loop,num_page = num_page)\n",
        "        else:\n",
        "            raise\n",
        "    rating_data = []\n",
        "    rating_list = soup.find_all('div',{'class':['comment__item par']})\n",
        "    if len(rating_list) > 0:\n",
        "        for rating in rating_list:\n",
        "            rating_data.append(rating_processing(rating))\n",
        "\n",
        "    return rating_data\n",
        "\n",
        "#rating_page_url = 'https://www.thegioididong.com/dtdd/realme-c12/danh-gia'\n",
        "#rating_list = get_rating(rating_page_url , SESSION, HEADERS, except_loop = 8,num_page = 1)\n",
        "#len(rating_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGFx8dEEK7hy"
      },
      "source": [
        "def crawling_rating_data():\n",
        "    print(\"main runing ...\")\n",
        "\n",
        "    categories = [('dtdd#c=42&o=9&pi=',14),('laptop#c=44&o=9&pi=',8),('may-tinh-bang#c=522&o=9&pi=',2)]\n",
        "\n",
        "    link_all_items = []\n",
        "    for type, end_page in categories:\n",
        "        link_all_items[len(link_all_items):] = get_all_item_in_page(type,end_page)\n",
        "\n",
        "    print('- Found {number:} items for all'.format(number = len(link_all_items)))\n",
        "\n",
        "\n",
        "    data = []\n",
        "    for link_item in link_all_items:\n",
        "        if '?src=osp' in link_item:\n",
        "            link_item = link_item.replace('?src=osp', \"\")\n",
        "\n",
        "        rating_page_url = 'https://www.thegioididong.com'+link_item+'/danh-gia'\n",
        "        print(rating_page_url)\n",
        "\n",
        "        t = True\n",
        "        n = 1\n",
        "        while t:\n",
        "            rating_data = get_rating(rating_page_url,SESSION, HEADERS, except_loop = 8, num_page = n)\n",
        "            if rating_data == []:\n",
        "                t = False\n",
        "            else:\n",
        "                data.append(rating_data)\n",
        "                n += 1\n",
        "\n",
        "    \n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzdyVip3YWoO"
      },
      "source": [
        "# crawling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPiSn7KoJy8x"
      },
      "source": [
        "rating_data = crawling_rating_data()\n",
        "# thegioididong_rating_data_path = '/content/drive/MyDrive/Colab Notebooks/dataset/kkdl/thegioididong_rating_data_12_06_21.json'\n",
        "# with open(thegioididong_rating_data_path, 'w', encoding='utf-8') as file: # file nằm ở thư mục cá nhân\n",
        "#     json.dump(rating_data, file,ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgzqHqRWFSO8"
      },
      "source": [
        "from datetime import datetime\n",
        "#print(datetime.today().strftime('%Y%m%d'))\n",
        "thegioididong_rating_data_path = '/content/drive/MyDrive/Colab Notebooks/thegioididong_rating_data_' + datetime.today().strftime('%Y%m%d') + '.json'\n",
        "with open(thegioididong_rating_data_path, 'w', encoding='utf-8') as file: # file nằm ở thư mục cá nhân\n",
        "    json.dump(rating_data, file,ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl7xEz0_4xuI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}